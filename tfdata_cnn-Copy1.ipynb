{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhila/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/nikhila/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/nikhila/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/nikhila/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/nikhila/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading files\n",
    "\n",
    "filenames = glob.glob(\"/home/nikhila/Quantiphi/all/train/*.jpg\")\n",
    "filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10222"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nikhila/Quantiphi/all/train/000bec180eb18c7604dcecc8fe0dba07.jpg',\n",
       " '/home/nikhila/Quantiphi/all/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = pd.read_csv('/home/nikhila/Quantiphi/all/labels.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       object\n",
       "breed    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_file.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_labels = np.unique(labels_file['breed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhila/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#unique labels to unique values to make one hot encoding with tfdata\n",
    "\n",
    "#SOURCE\n",
    "\n",
    "#http://benalexkeen.com/mapping-categorical-data-in-pandas/\n",
    "\n",
    "uniq_vals = labels_file.breed.astype(\"category\", categories = unq_labels).cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = uniq_vals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 37, 85, ...,  3, 75, 28], dtype=int8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10222"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = tf.one_hot(list_labels,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((filenames,list_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename,label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    # Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.image.decode_jpeg(image_string,channels=3)\n",
    "    #this will convert image values to float values in [0,1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    resized_image = tf.image.resize_images(image,[224,224])\n",
    "    \n",
    "    return resized_image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_preprocess(image, label):\n",
    " #   image = tf.image.random_brightness\n",
    "  #  image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "\n",
    "    # Make sure the image is still in [0, 1]\n",
    "   # image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    #return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()\n",
    "x,y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "learning_rate = 0.0001\n",
    "num_batches = int(len(filenames)/batch_size)\n",
    "\n",
    "conv1 = tf.layers.conv2d(x, 32, 3, strides = 1,activation=tf.nn.relu)\n",
    "conv1 = tf.layers.max_pooling2d(conv1, 2, 2,padding='same')\n",
    "conv1 = tf.layers.batch_normalization(conv1)\n",
    "\n",
    "\n",
    "conv2 = tf.layers.conv2d(conv1, 64, 5,strides=1, activation=tf.nn.relu)\n",
    "conv2 = tf.layers.max_pooling2d(conv2, 2, 2,padding='same')\n",
    "conv2 = tf.layers.batch_normalization(conv2)\n",
    "\n",
    "\n",
    "conv3 = tf.layers.conv2d(conv2,128, 5,strides=1, activation=tf.nn.relu)\n",
    "conv3 = tf.layers.max_pooling2d(conv3, 2, 2)\n",
    "conv3 = tf.layers.batch_normalization(conv3)\n",
    "\n",
    "#flatten layer\n",
    "fc1 = tf.contrib.layers.flatten(conv3)\n",
    "\n",
    "#fully connected dense layer\n",
    "fc1 = tf.layers.dense(fc1,2048)\n",
    "\n",
    "fc2 = tf.layers.dense(fc1,512)\n",
    "\n",
    "logits_train = tf.layers.dense(fc2,120)\n",
    "\n",
    "#pred = tf.nn.softmax(logits_train)\n",
    "\n",
    "predict_classes = tf.argmax(logits_train, axis = 1)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_train,labels=y))\n",
    "\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "compare = tf.equal(predict_classes,tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(compare,tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0  loss:  4.7569504 accuracy: 0.0625\n",
      "batch:  10  loss:  4.9778156 accuracy: 0.03125\n",
      "batch:  20  loss:  4.7804747 accuracy: 0.03125\n",
      "batch:  30  loss:  4.8544836 accuracy: 0.0\n",
      "batch:  40  loss:  4.7974496 accuracy: 0.03125\n",
      "batch:  50  loss:  4.760803 accuracy: 0.0\n",
      "batch:  60  loss:  4.7447214 accuracy: 0.03125\n",
      "batch:  70  loss:  4.7597055 accuracy: 0.0\n",
      "batch:  80  loss:  4.779726 accuracy: 0.0\n",
      "batch:  90  loss:  4.736282 accuracy: 0.0\n",
      "batch:  100  loss:  4.7319546 accuracy: 0.0\n",
      "batch:  110  loss:  4.8164177 accuracy: 0.03125\n",
      "batch:  120  loss:  4.724188 accuracy: 0.0\n",
      "batch:  130  loss:  4.695612 accuracy: 0.0625\n",
      "batch:  140  loss:  4.470126 accuracy: 0.0625\n",
      "batch:  150  loss:  4.807123 accuracy: 0.0\n",
      "batch:  160  loss:  4.528813 accuracy: 0.03125\n",
      "batch:  170  loss:  4.4893622 accuracy: 0.0625\n",
      "batch:  180  loss:  4.5710745 accuracy: 0.0\n",
      "batch:  190  loss:  4.8603015 accuracy: 0.0\n",
      "batch:  200  loss:  4.59149 accuracy: 0.0\n",
      "batch:  210  loss:  4.665 accuracy: 0.03125\n",
      "batch:  220  loss:  4.7366514 accuracy: 0.03125\n",
      "batch:  230  loss:  4.604447 accuracy: 0.0\n",
      "batch:  240  loss:  4.6295676 accuracy: 0.0\n",
      "batch:  250  loss:  4.6418886 accuracy: 0.0\n",
      "batch:  260  loss:  4.488967 accuracy: 0.03125\n",
      "batch:  270  loss:  4.61379 accuracy: 0.03125\n",
      "batch:  280  loss:  4.386201 accuracy: 0.0\n",
      "batch:  290  loss:  4.2183504 accuracy: 0.0625\n",
      "batch:  300  loss:  4.5710573 accuracy: 0.03125\n",
      "batch:  310  loss:  4.2771244 accuracy: 0.03125\n",
      "batch:  0  loss:  4.1160116 accuracy: 0.0625\n",
      "batch:  10  loss:  4.483936 accuracy: 0.03125\n",
      "batch:  20  loss:  4.216977 accuracy: 0.09375\n",
      "batch:  30  loss:  4.439748 accuracy: 0.0\n",
      "batch:  40  loss:  4.307342 accuracy: 0.15625\n",
      "batch:  50  loss:  3.8140385 accuracy: 0.125\n",
      "batch:  60  loss:  4.015651 accuracy: 0.0625\n",
      "batch:  70  loss:  3.6638007 accuracy: 0.21875\n",
      "batch:  80  loss:  3.8784742 accuracy: 0.09375\n",
      "batch:  90  loss:  3.7934546 accuracy: 0.09375\n",
      "batch:  100  loss:  3.4911191 accuracy: 0.21875\n",
      "batch:  110  loss:  3.6895459 accuracy: 0.21875\n",
      "batch:  120  loss:  3.7916408 accuracy: 0.09375\n",
      "batch:  130  loss:  3.5742486 accuracy: 0.28125\n",
      "batch:  140  loss:  3.4877372 accuracy: 0.21875\n",
      "batch:  150  loss:  3.8241773 accuracy: 0.09375\n",
      "batch:  160  loss:  3.304717 accuracy: 0.28125\n",
      "batch:  170  loss:  3.1732767 accuracy: 0.3125\n",
      "batch:  180  loss:  3.376027 accuracy: 0.21875\n",
      "batch:  190  loss:  4.5287704 accuracy: 0.03125\n",
      "batch:  200  loss:  3.3051236 accuracy: 0.375\n",
      "batch:  210  loss:  3.7449253 accuracy: 0.15625\n",
      "batch:  220  loss:  3.923005 accuracy: 0.09375\n",
      "batch:  230  loss:  3.3242285 accuracy: 0.25\n",
      "batch:  240  loss:  3.8346186 accuracy: 0.125\n",
      "batch:  250  loss:  3.7588453 accuracy: 0.15625\n",
      "batch:  260  loss:  3.3589473 accuracy: 0.1875\n",
      "batch:  270  loss:  4.109835 accuracy: 0.09375\n",
      "batch:  280  loss:  3.123647 accuracy: 0.3125\n",
      "batch:  290  loss:  3.220265 accuracy: 0.28125\n",
      "batch:  300  loss:  3.5246754 accuracy: 0.1875\n",
      "batch:  310  loss:  3.477261 accuracy: 0.21875\n",
      "batch:  0  loss:  2.278884 accuracy: 0.59375\n",
      "batch:  10  loss:  3.202559 accuracy: 0.15625\n",
      "batch:  20  loss:  2.609722 accuracy: 0.34375\n",
      "batch:  30  loss:  2.833137 accuracy: 0.28125\n",
      "batch:  40  loss:  2.7011397 accuracy: 0.375\n",
      "batch:  50  loss:  2.7541702 accuracy: 0.34375\n",
      "batch:  60  loss:  2.9201055 accuracy: 0.25\n",
      "batch:  70  loss:  2.3974876 accuracy: 0.46875\n",
      "batch:  80  loss:  2.4261653 accuracy: 0.34375\n",
      "batch:  90  loss:  2.0386493 accuracy: 0.46875\n",
      "batch:  100  loss:  1.6441483 accuracy: 0.5625\n",
      "batch:  110  loss:  2.0520797 accuracy: 0.53125\n",
      "batch:  120  loss:  2.1245973 accuracy: 0.40625\n",
      "batch:  130  loss:  1.7979081 accuracy: 0.5625\n",
      "batch:  140  loss:  1.5334902 accuracy: 0.59375\n",
      "batch:  150  loss:  2.3305097 accuracy: 0.46875\n",
      "batch:  160  loss:  1.6837139 accuracy: 0.5625\n",
      "batch:  170  loss:  1.8161833 accuracy: 0.625\n",
      "batch:  180  loss:  2.2156186 accuracy: 0.4375\n",
      "batch:  190  loss:  2.322184 accuracy: 0.46875\n",
      "batch:  200  loss:  2.154341 accuracy: 0.5\n",
      "batch:  210  loss:  2.1243033 accuracy: 0.46875\n",
      "batch:  220  loss:  1.7632873 accuracy: 0.53125\n",
      "batch:  230  loss:  1.7086364 accuracy: 0.53125\n",
      "batch:  240  loss:  2.1297083 accuracy: 0.53125\n",
      "batch:  250  loss:  1.362499 accuracy: 0.625\n",
      "batch:  260  loss:  1.3292207 accuracy: 0.59375\n",
      "batch:  270  loss:  2.106469 accuracy: 0.40625\n",
      "batch:  280  loss:  1.161984 accuracy: 0.71875\n",
      "batch:  290  loss:  1.6141176 accuracy: 0.5625\n",
      "batch:  300  loss:  1.566975 accuracy: 0.625\n",
      "batch:  310  loss:  1.818784 accuracy: 0.5625\n",
      "batch:  0  loss:  0.6255816 accuracy: 0.90625\n",
      "batch:  10  loss:  1.1364212 accuracy: 0.65625\n",
      "batch:  20  loss:  0.91301537 accuracy: 0.8125\n",
      "batch:  30  loss:  0.51276195 accuracy: 0.90625\n",
      "batch:  40  loss:  1.0878606 accuracy: 0.78125\n",
      "batch:  50  loss:  0.98894656 accuracy: 0.65625\n",
      "batch:  60  loss:  0.8971086 accuracy: 0.78125\n",
      "batch:  70  loss:  1.0554458 accuracy: 0.71875\n",
      "batch:  80  loss:  0.6239157 accuracy: 0.875\n",
      "batch:  90  loss:  1.0446676 accuracy: 0.65625\n",
      "batch:  100  loss:  0.3242157 accuracy: 0.90625\n",
      "batch:  110  loss:  0.7955064 accuracy: 0.8125\n",
      "batch:  120  loss:  0.5431318 accuracy: 0.84375\n",
      "batch:  130  loss:  0.54554313 accuracy: 0.84375\n",
      "batch:  140  loss:  0.51338243 accuracy: 0.875\n",
      "batch:  150  loss:  1.3747071 accuracy: 0.75\n",
      "batch:  160  loss:  0.62201124 accuracy: 0.8125\n",
      "batch:  170  loss:  0.63367355 accuracy: 0.78125\n",
      "batch:  180  loss:  1.1512837 accuracy: 0.71875\n",
      "batch:  190  loss:  0.551105 accuracy: 0.84375\n",
      "batch:  200  loss:  0.7420722 accuracy: 0.78125\n",
      "batch:  210  loss:  0.79898965 accuracy: 0.84375\n",
      "batch:  220  loss:  0.67289037 accuracy: 0.875\n",
      "batch:  230  loss:  0.9844383 accuracy: 0.6875\n",
      "batch:  240  loss:  0.6744632 accuracy: 0.84375\n",
      "batch:  250  loss:  0.11483372 accuracy: 1.0\n",
      "batch:  260  loss:  0.35252815 accuracy: 0.9375\n",
      "batch:  270  loss:  0.4798274 accuracy: 0.90625\n",
      "batch:  280  loss:  0.3610977 accuracy: 0.84375\n",
      "batch:  290  loss:  0.7531971 accuracy: 0.75\n",
      "batch:  300  loss:  0.751655 accuracy: 0.84375\n",
      "batch:  310  loss:  0.4967885 accuracy: 0.84375\n",
      "batch:  0  loss:  0.741503 accuracy: 0.78125\n",
      "batch:  10  loss:  0.225372 accuracy: 0.96875\n",
      "batch:  20  loss:  0.34043884 accuracy: 0.90625\n",
      "batch:  30  loss:  0.711198 accuracy: 0.78125\n",
      "batch:  40  loss:  0.4399426 accuracy: 0.875\n",
      "batch:  50  loss:  0.3607555 accuracy: 0.90625\n",
      "batch:  60  loss:  1.0489414 accuracy: 0.71875\n",
      "batch:  70  loss:  0.46188435 accuracy: 0.90625\n",
      "batch:  80  loss:  0.3279392 accuracy: 0.9375\n",
      "batch:  90  loss:  0.3477562 accuracy: 0.90625\n",
      "batch:  100  loss:  0.23194909 accuracy: 0.9375\n",
      "batch:  110  loss:  0.5876761 accuracy: 0.84375\n",
      "batch:  120  loss:  0.4380859 accuracy: 0.875\n",
      "batch:  130  loss:  0.088204086 accuracy: 1.0\n",
      "batch:  140  loss:  0.40052426 accuracy: 0.875\n",
      "batch:  150  loss:  0.3729786 accuracy: 0.90625\n",
      "batch:  160  loss:  0.28731844 accuracy: 0.90625\n",
      "batch:  170  loss:  0.23848012 accuracy: 0.9375\n",
      "batch:  180  loss:  0.28703362 accuracy: 0.9375\n",
      "batch:  190  loss:  0.16916755 accuracy: 0.96875\n",
      "batch:  200  loss:  0.29457325 accuracy: 0.90625\n",
      "batch:  210  loss:  0.25826252 accuracy: 0.96875\n",
      "batch:  220  loss:  0.15430109 accuracy: 0.96875\n",
      "batch:  230  loss:  0.53497034 accuracy: 0.9375\n",
      "batch:  240  loss:  0.083218545 accuracy: 0.96875\n",
      "batch:  250  loss:  0.06216579 accuracy: 1.0\n",
      "batch:  260  loss:  0.13306302 accuracy: 1.0\n",
      "batch:  270  loss:  0.27600634 accuracy: 0.90625\n",
      "batch:  280  loss:  0.20660642 accuracy: 0.9375\n",
      "batch:  290  loss:  0.17333299 accuracy: 0.9375\n",
      "batch:  300  loss:  0.2107462 accuracy: 0.90625\n",
      "batch:  310  loss:  0.3598192 accuracy: 0.9375\n",
      "batch:  0  loss:  0.17709632 accuracy: 0.9375\n",
      "batch:  10  loss:  0.16913866 accuracy: 0.9375\n",
      "batch:  20  loss:  0.111954115 accuracy: 0.96875\n",
      "batch:  30  loss:  0.64586353 accuracy: 0.8125\n",
      "batch:  40  loss:  0.23856322 accuracy: 0.90625\n",
      "batch:  50  loss:  0.10042724 accuracy: 1.0\n",
      "batch:  60  loss:  0.49455532 accuracy: 0.9375\n",
      "batch:  70  loss:  0.14282498 accuracy: 0.96875\n",
      "batch:  80  loss:  0.059512906 accuracy: 1.0\n",
      "batch:  90  loss:  0.050648518 accuracy: 1.0\n",
      "batch:  100  loss:  0.1917549 accuracy: 0.90625\n",
      "batch:  110  loss:  0.19858244 accuracy: 0.9375\n",
      "batch:  120  loss:  0.13679849 accuracy: 0.96875\n",
      "batch:  130  loss:  0.10161734 accuracy: 0.96875\n",
      "batch:  140  loss:  0.15980121 accuracy: 0.9375\n",
      "batch:  150  loss:  0.13193578 accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  160  loss:  0.26558954 accuracy: 0.9375\n",
      "batch:  170  loss:  0.1573348 accuracy: 1.0\n",
      "batch:  180  loss:  0.123371296 accuracy: 1.0\n",
      "batch:  190  loss:  0.0969233 accuracy: 0.96875\n",
      "batch:  200  loss:  0.06420777 accuracy: 1.0\n",
      "batch:  210  loss:  0.19702192 accuracy: 0.9375\n",
      "batch:  220  loss:  0.17542401 accuracy: 0.9375\n",
      "batch:  230  loss:  0.0741895 accuracy: 1.0\n",
      "batch:  240  loss:  0.11282713 accuracy: 1.0\n",
      "batch:  250  loss:  0.21360675 accuracy: 0.90625\n",
      "batch:  260  loss:  0.11646328 accuracy: 0.9375\n",
      "batch:  270  loss:  0.1723974 accuracy: 0.9375\n",
      "batch:  280  loss:  0.09717065 accuracy: 0.96875\n",
      "batch:  290  loss:  0.14097321 accuracy: 0.96875\n",
      "batch:  300  loss:  0.015138797 accuracy: 1.0\n",
      "batch:  310  loss:  0.164006 accuracy: 0.96875\n",
      "batch:  0  loss:  0.026214745 accuracy: 1.0\n",
      "batch:  10  loss:  0.07211636 accuracy: 1.0\n",
      "batch:  20  loss:  0.051663823 accuracy: 1.0\n",
      "batch:  30  loss:  0.17636123 accuracy: 0.9375\n",
      "batch:  40  loss:  0.06561159 accuracy: 1.0\n",
      "batch:  50  loss:  0.04156193 accuracy: 1.0\n",
      "batch:  60  loss:  0.33833334 accuracy: 0.96875\n",
      "batch:  70  loss:  0.0944271 accuracy: 0.96875\n",
      "batch:  80  loss:  0.029523702 accuracy: 1.0\n",
      "batch:  90  loss:  0.088892676 accuracy: 0.96875\n",
      "batch:  100  loss:  0.26807487 accuracy: 0.9375\n",
      "batch:  110  loss:  0.0736968 accuracy: 1.0\n",
      "batch:  120  loss:  0.064403586 accuracy: 0.96875\n",
      "batch:  130  loss:  0.052662127 accuracy: 1.0\n",
      "batch:  140  loss:  0.032851055 accuracy: 1.0\n",
      "batch:  150  loss:  0.056682788 accuracy: 1.0\n",
      "batch:  160  loss:  0.108871244 accuracy: 0.9375\n",
      "batch:  170  loss:  0.14246756 accuracy: 0.9375\n",
      "batch:  180  loss:  0.07036794 accuracy: 1.0\n",
      "batch:  190  loss:  0.022509623 accuracy: 1.0\n",
      "batch:  200  loss:  0.06386385 accuracy: 1.0\n",
      "batch:  210  loss:  0.037016395 accuracy: 1.0\n",
      "batch:  220  loss:  0.06507814 accuracy: 0.96875\n",
      "batch:  230  loss:  0.15920405 accuracy: 0.96875\n",
      "batch:  240  loss:  0.12332396 accuracy: 0.9375\n",
      "batch:  250  loss:  0.023083877 accuracy: 1.0\n",
      "batch:  260  loss:  0.015657807 accuracy: 1.0\n",
      "batch:  270  loss:  0.12672001 accuracy: 0.96875\n",
      "batch:  280  loss:  0.009716725 accuracy: 1.0\n",
      "batch:  290  loss:  0.030065177 accuracy: 1.0\n",
      "batch:  300  loss:  0.006351991 accuracy: 1.0\n",
      "batch:  310  loss:  0.110561445 accuracy: 0.96875\n",
      "batch:  0  loss:  0.18441138 accuracy: 0.90625\n",
      "batch:  10  loss:  0.03728423 accuracy: 1.0\n",
      "batch:  20  loss:  0.13558862 accuracy: 0.9375\n",
      "batch:  30  loss:  0.25463554 accuracy: 0.96875\n",
      "batch:  40  loss:  0.015886795 accuracy: 1.0\n",
      "batch:  50  loss:  0.041838955 accuracy: 1.0\n",
      "batch:  60  loss:  0.075769424 accuracy: 1.0\n",
      "batch:  70  loss:  0.32376072 accuracy: 0.9375\n",
      "batch:  80  loss:  0.13700606 accuracy: 0.96875\n",
      "batch:  90  loss:  0.05578372 accuracy: 1.0\n",
      "batch:  100  loss:  0.40709203 accuracy: 0.96875\n",
      "batch:  110  loss:  0.051629424 accuracy: 1.0\n",
      "batch:  120  loss:  0.027001273 accuracy: 1.0\n",
      "batch:  130  loss:  0.09258946 accuracy: 0.96875\n",
      "batch:  140  loss:  0.12144009 accuracy: 0.96875\n",
      "batch:  150  loss:  0.057909634 accuracy: 0.96875\n",
      "batch:  160  loss:  0.051394694 accuracy: 1.0\n",
      "batch:  170  loss:  0.02174769 accuracy: 1.0\n",
      "batch:  180  loss:  0.098072514 accuracy: 0.96875\n",
      "batch:  190  loss:  0.017592816 accuracy: 1.0\n",
      "batch:  200  loss:  0.014354115 accuracy: 1.0\n",
      "batch:  210  loss:  0.030339452 accuracy: 1.0\n",
      "batch:  220  loss:  0.07025518 accuracy: 0.96875\n",
      "batch:  230  loss:  0.08856636 accuracy: 0.96875\n",
      "batch:  240  loss:  0.013788398 accuracy: 1.0\n",
      "batch:  250  loss:  0.01831692 accuracy: 1.0\n",
      "batch:  260  loss:  0.03681256 accuracy: 1.0\n",
      "batch:  270  loss:  0.012243219 accuracy: 1.0\n",
      "batch:  280  loss:  0.017948959 accuracy: 1.0\n",
      "batch:  290  loss:  0.010562493 accuracy: 1.0\n",
      "batch:  300  loss:  0.009612564 accuracy: 1.0\n",
      "batch:  310  loss:  0.022130212 accuracy: 1.0\n",
      "batch:  0  loss:  0.012735786 accuracy: 1.0\n",
      "batch:  10  loss:  0.27028522 accuracy: 0.9375\n",
      "batch:  20  loss:  0.018834485 accuracy: 1.0\n",
      "batch:  30  loss:  0.017291931 accuracy: 1.0\n",
      "batch:  40  loss:  0.066058286 accuracy: 0.96875\n",
      "batch:  50  loss:  0.02097773 accuracy: 1.0\n",
      "batch:  60  loss:  0.1548264 accuracy: 0.96875\n",
      "batch:  70  loss:  0.031736672 accuracy: 1.0\n",
      "batch:  80  loss:  0.017519133 accuracy: 1.0\n",
      "batch:  90  loss:  0.0074166805 accuracy: 1.0\n",
      "batch:  100  loss:  0.2717887 accuracy: 0.96875\n",
      "batch:  110  loss:  0.031215113 accuracy: 1.0\n",
      "batch:  120  loss:  0.016062338 accuracy: 1.0\n",
      "batch:  130  loss:  0.017804334 accuracy: 1.0\n",
      "batch:  140  loss:  0.04689852 accuracy: 1.0\n",
      "batch:  150  loss:  0.07816601 accuracy: 0.96875\n",
      "batch:  160  loss:  0.10184228 accuracy: 0.96875\n",
      "batch:  170  loss:  0.017907217 accuracy: 1.0\n",
      "batch:  180  loss:  0.18413743 accuracy: 0.96875\n",
      "batch:  190  loss:  0.182788 accuracy: 0.9375\n",
      "batch:  200  loss:  0.021628978 accuracy: 1.0\n",
      "batch:  210  loss:  0.008244753 accuracy: 1.0\n",
      "batch:  220  loss:  0.011672793 accuracy: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6c66b901a039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"batch: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    n_epochs = 100\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(n_epochs):\n",
    "        sess.run(iterator.initializer)\n",
    "        for j in range(num_batches):\n",
    "            _, loss_val,acc = sess.run([train_op, loss_op, accuracy])\n",
    "            if j%10 == 0:\n",
    "                print (\"batch: \",j,\" loss: \",loss_val, \"accuracy:\", acc)\n",
    "        print (\"epoch: \",i,\" loss: \",loss_val, \"accuracy:\", acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
